# Web-Scraping-Project


## Objective

The objective of web scraping is to automate the process of extracting large amounts of data from websites, enabling efficient and systematic collection of information that can be used for various purposes such as data analysis, market research, content aggregation, and more.


### Skills Learned

- Data Extraction: Efficiently extracting structured data from unstructured web pages using various tools and techniques.
- Automation: Developing scripts to automate the process of data retrieval and storage.
- HTML/CSS Parsing: Understanding and navigating HTML and CSS structures to locate and scrape specific data elements.
- Handling Web Requests: Managing HTTP requests and responses, including handling pagination, cookies, and headers.

### Tools Used

-BeautifulSoup: A Python library for parsing HTML and XML documents to extract data.
-Requests: A simple HTTP library for Python to make web requests and download web pages.
-Dorks-Eye: a Python3-based tool designed to identify vulnerable links using Google Dorks.


## Steps

Dorks-Eye:

<img width="830" alt="dorks eye started" src="https://github.com/shikha1149myprojects/Web-Scraping-Project/assets/173707209/323d75de-baa2-457c-a98f-d6e437d0e41d">

List of 10 vulnerable websites:

<img width="733" alt="list of 10 vulnerable websites" src="https://github.com/shikha1149myprojects/Web-Scraping-Project/assets/173707209/1569fe3b-37f1-4c05-b2a5-f8c9ef925c73">

Conf Directory:

<img width="1052" alt="conf directory" src="https://github.com/shikha1149myprojects/Web-Scraping-Project/assets/173707209/a0a57282-428d-437d-86f7-8d3eec62bd26">







